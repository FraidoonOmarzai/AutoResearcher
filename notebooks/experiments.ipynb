{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4ea78e",
   "metadata": {},
   "source": [
    "<h1 align=center> Autonomous Research Assistant Agents </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea0b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from typing import Annotated, TypedDict, List, Optional\n",
    "from typing_extensions import Literal\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0715ec65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, so I need to figure out what multi-agent types are. I remember hearing about agents in AI before, but I\\'m not exactly sure what \"types\" mean in this context. Let me start by breaking down the term. \"Multi-agent\" probably means multiple agents working together or in some system. \"Types\" could refer to different categories or classifications of these agents. So, putting it together, multi-agent types might be the various kinds of agents that can exist within a multi-agent system.\\n\\nI think the user provided a detailed explanation before, so maybe I should go through that to make sure I understand. They listed several types like Reactive, Cognitive, Hybrid, Autonomous, etc. I should probably go through each of these to get a clearer picture.\\n\\nStarting with Reactive Agents: These are simple and react to the environment without complex reasoning. They use predefined rules, like in video games where an enemy follows a player based on certain conditions. I guess this is the most basic type, where the agent doesn\\'t plan ahead or learn, just reacts.\\n\\nNext, Cognitive Agents: These seem more complex. They can reason, plan, and have goals. They might use techniques like BDI (Beliefs, Desires, Intentions) or planning algorithms. So, these agents are smarter and can handle more dynamic environments, maybe like personal assistants that understand user needs over time.\\n\\nHybrid Agents combine both reactive and cognitive aspects. They have a hierarchical structure, allowing them to handle both immediate reactions and long-term planning. This makes sense because in real-world scenarios, agents might need to react quickly but also plan strategically. Maybe something like an autonomous vehicle that needs to react to immediate obstacles but also plan the route.\\n\\nAutonomous Agents operate independently without human intervention. They can perceive the environment, make decisions, and act. They could be self-aware, which I think means they have a sense of their own state and needs. Examples might include drones or robots that work on their own.\\n\\nHeterogeneous Agents have different capabilities and roles. This is important in systems where agents specialize in tasks. For example, in a smart city, some agents might manage traffic, others handle energy, and so on. Each has their own expertise and can interact with others to achieve common goals.\\n\\nHomogeneous Agents are the opposite—they are identical in capabilities and roles. This could simplify the system, maybe in a swarm of drones where each does the same task, but together they achieve a complex outcome like mapping an area.\\n\\nCooperative Agents work together to achieve common goals. They might share information and coordinate actions. An example could be a team of robots working together in a factory to assemble a product. They need to communicate and collaborate effectively.\\n\\nCompetitive Agents, on the other hand, pursue their own goals which might conflict with others. This could be seen in game playing agents or in market simulations where agents compete for resources. It\\'s like agents in an auction trying to outbid each other.\\n\\nLearning Agents can improve their performance over time through various algorithms. They might use reinforcement learning to figure out the best actions in a given situation. This is like a recommendation system that gets better as it learns user preferences.\\n\\nMobile Agents can move across different environments or networks. They carry their state and code with them, which allows for more flexibility. Maybe like a software agent that moves between different servers to perform tasks.\\n\\nSocial Agents interact with humans or other agents using social behaviors. They can understand emotions and communicate effectively. Examples would be chatbots or virtual assistants that need to interact with people in a helpful way.\\n\\nAdaptive Agents adjust their behavior based on changes in the environment or user needs. They might use machine learning to modify their actions over time. This could be useful in systems that need to respond to dynamic conditions, like traffic management.\\n\\nSpecialized vs. Generalized Agents: Specialized ones are designed for specific tasks, while generalized can handle a variety of tasks. Specialized might be more efficient for their task, while generalized offer flexibility.\\n\\nI think I have a basic grasp now. Each type of agent serves different purposes and can be used in various applications. Understanding these types helps in designing systems where agents can work together effectively, whether they\\'re reacting, planning, learning, or interacting socially. It\\'s also important to consider whether agents need to cooperate or compete, and whether they should be homogeneous or heterogeneous based on the system\\'s requirements.\\n\\nI wonder how these types are determined. Is it based on the agent\\'s architecture, its capabilities, or its role in the system? It seems like it\\'s a combination of these factors. For example, a cognitive agent\\'s architecture includes reasoning and planning, which sets it apart from a reactive agent that just follows rules.\\n\\nAlso, how do these types interact in a multi-agent system? If you have both reactive and cognitive agents, how do they communicate and coordinate? Maybe through some middleware or a common framework that allows them to exchange information.\\n\\nAnother thought: in a real-world application, an agent might embody multiple types. For instance, an autonomous drone might be both a mobile agent and a learning agent, adapting its navigation based on obstacles it encounters over time.\\n\\nI should also consider the challenges. For example, managing a system with heterogeneous and competitive agents might require robust communication protocols and conflict resolution mechanisms. Whereas a homogeneous and cooperative system might be simpler but less flexible.\\n\\nIn terms of development, choosing the right type of agents depends on the problem\\'s complexity, the environment\\'s dynamics, and the tasks that need to be performed. A developer might opt for reactive agents for simple, real-time tasks and cognitive agents for more complex, planning-intensive tasks.\\n\\nI\\'m also thinking about examples beyond the ones given. Maybe in a smart grid, you could have a mix of reactive agents that respond to immediate power fluctuations and cognitive agents that plan energy distribution for the next day. Or in healthcare, social agents could assist patients, while learning agents analyze data to improve treatment plans.\\n\\nI should also think about the learning aspect. If agents can learn, how do they interact with each other? Do they share knowledge, or does each learn independently? In some cases, agents might learn collaboratively, leading to better system-wide performance over time.\\n\\nLastly, security and trust are important. In a system with competitive or heterogeneous agents, ensuring that agents can trust each other and that the system is secure becomes crucial. Especially if these agents are handling sensitive information or critical tasks.\\n\\nI think I\\'ve covered the main points. Each multi-agent type brings different capabilities and challenges, and understanding them helps in designing effective multi-agent systems tailored to specific applications.\\n</think>\\n\\nMulti-agent systems encompass a variety of agent types, each designed to fulfill specific roles and functionalities within a system. These types are categorized based on their architectures, behaviors, and interactions. Here\\'s an organized overview of the key multi-agent types:\\n\\n1. **Reactive Agents**: These agents respond to environmental stimuli using predefined rules without complex reasoning. They are suitable for real-time reactions, such as NPCs in video games.\\n\\n2. **Cognitive Agents**: Equipped with reasoning and planning capabilities, these agents use architectures like BDI to handle dynamic environments, exemplified by personal assistants.\\n\\n3. **Hybrid Agents**: Combining reactive and cognitive elements, they manage both immediate reactions and long-term planning, as seen in autonomous vehicles.\\n\\n4. **Autonomous Agents**: Operating independently, they perceive, decide, and act without human intervention, often self-aware, like drones or robots.\\n\\n5. **Heterogeneous Agents**: Diverse in capabilities and roles, they specialize in tasks, such as smart city systems managing traffic and energy.\\n\\n6. **Homogeneous Agents**: Identical in capabilities, they simplify systems through uniformity, like swarms of drones mapping areas.\\n\\n7. **Cooperative Agents**: Working together towards common goals, they collaborate, as in factory robots assembling products.\\n\\n8. **Competitive Agents**: Pursuing individual goals, often conflicting, seen in game playing or market simulations.\\n\\n9. **Learning Agents**: Improving over time using algorithms like reinforcement learning, such as recommendation systems adapting to user preferences.\\n\\n10. **Mobile Agents**: Capable of moving across environments, carrying their state and code, useful in distributed systems.\\n\\n11. **Social Agents**: Interacting with humans using social behaviors, like chatbots or virtual assistants.\\n\\n12. **Adaptive Agents**: Adjusting behavior based on environmental changes, useful in dynamic systems like traffic management.\\n\\n13. **Specialized vs. Generalized Agents**: Specialized agents excel in specific tasks, while generalized agents offer flexibility across various tasks.\\n\\nIn designing multi-agent systems, the choice of agent type depends on problem complexity, environmental dynamics, and task requirements. Effective systems may integrate multiple types, such as combining reactive and learning agents. Challenges include communication protocols, conflict resolution, security, and trust, especially in heterogeneous or competitive environments. Developers must consider these factors to create systems tailored to specific applications, ensuring efficient and secure interactions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1809, 'prompt_tokens': 10, 'total_tokens': 1819, 'completion_time': 8.987146318, 'prompt_time': 0.001042082, 'queue_time': 0.801977056, 'total_time': 8.9881884}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--50f32a61-3602-4bd2-891b-183ba2d78cfe-0', usage_metadata={'input_tokens': 10, 'output_tokens': 1809, 'total_tokens': 1819})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model_name=\"deepseek-r1-distill-llama-70b\")\n",
    "\n",
    "results = llm.invoke(\"tell me about multi agent types?\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17126bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-Bm4UXNDBl28kKIgq2JFO0VAlTKkjF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b2bcccbc-631f-48d3-9b61-9b5914ee4e62-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize LLM (use gpt-4 or gpt-3.5-turbo)\n",
    "llm2 = ChatOpenAI(model=\"gpt-4\", temperature=0.2)\n",
    "llm2.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70af939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arxiv_papers(topic: str, max_results: int = 3) -> list:\n",
    "    search = arxiv.Search(\n",
    "        query=topic,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = []\n",
    "    for result in search.results():\n",
    "        paper_info = {\n",
    "            \"title\": result.title,\n",
    "            \"authors\": [author.name for author in result.authors],\n",
    "            \"summary\": result.summary,\n",
    "            \"url\": result.entry_id,\n",
    "            \"published\": result.published.date()\n",
    "        }\n",
    "        papers.append(paper_info)\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99483f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\44787\\AppData\\Local\\Temp\\ipykernel_30328\\3121392185.py:9: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Paper 1: Aligning Large Language Models with Healthcare Stakeholders: A Pathway to Trustworthy AI Integration\n",
      "👨‍🔬 Authors: Kexin Ding, Mu Zhou, Akshay Chaudhari, Shaoting Zhang, Dimitris N. Metaxas\n",
      "🗓️ Published: 2025-05-02\n",
      "🔗 URL: http://arxiv.org/abs/2505.02848v1\n",
      "📄 Abstract: The wide exploration of large language models (LLMs) raises the awareness of\n",
      "alignment between healthcare stakeholder preferences and model outputs. This\n",
      "alignment becomes a crucial foundation to empower the healthcare workflow\n",
      "effectively, safely, and responsibly. Yet the varying behaviors of LLMs may not\n",
      "always match with healthcare stakeholders' knowledge, demands, and values. To\n",
      "enable a human-AI alignment, healthcare stakeholders will need to perform\n",
      "essential roles in guiding and enhancing...\n",
      "\n",
      "📄 Paper 2: An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT\n",
      "👨‍🔬 Authors: Shyni Sharaf, V. S. Anoop\n",
      "🗓️ Published: 2023-10-11\n",
      "🔗 URL: http://arxiv.org/abs/2310.07282v2\n",
      "📄 Abstract: This paper conducts a comprehensive investigation into applying large\n",
      "language models, particularly on BioBERT, in healthcare. It begins with\n",
      "thoroughly examining previous natural language processing (NLP) approaches in\n",
      "healthcare, shedding light on the limitations and challenges these methods\n",
      "face. Following that, this research explores the path that led to the\n",
      "incorporation of BioBERT into healthcare applications, highlighting its\n",
      "suitability for addressing the specific requirements of tasks r...\n",
      "\n",
      "📄 Paper 3: The Role of Language Models in Modern Healthcare: A Comprehensive Review\n",
      "👨‍🔬 Authors: Amna Khalid, Ayma Khalid, Umar Khalid\n",
      "🗓️ Published: 2024-09-25\n",
      "🔗 URL: http://arxiv.org/abs/2409.16860v1\n",
      "📄 Abstract: The application of large language models (LLMs) in healthcare has gained\n",
      "significant attention due to their ability to process complex medical data and\n",
      "provide insights for clinical decision-making. These models have demonstrated\n",
      "substantial capabilities in understanding and generating natural language,\n",
      "which is crucial for medical documentation, diagnostics, and patient\n",
      "interaction. This review examines the trajectory of language models from their\n",
      "early stages to the current state-of-the-art LL...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic = \"Large Language Models in Healthcare\"\n",
    "papers = get_arxiv_papers(topic)\n",
    "\n",
    "for i, paper in enumerate(papers):\n",
    "    print(f\"📄 Paper {i+1}: {paper['title']}\")\n",
    "    print(f\"👨‍🔬 Authors: {', '.join(paper['authors'])}\")\n",
    "    print(f\"🗓️ Published: {paper['published']}\")\n",
    "    print(f\"🔗 URL: {paper['url']}\")\n",
    "    print(f\"📄 Abstract: {paper['summary'][:500]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f9bac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain prompt template\n",
    "summary_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an AI research assistant. Read the abstract below and summarize the key points.\n",
    "\n",
    "Abstract:\n",
    "\"{abstract}\"\n",
    "\n",
    "Summarize in 3 bullet points.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "summarizer_chain = summary_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f775409",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_papers = []\n",
    "\n",
    "for paper in papers:\n",
    "    abstract = paper[\"summary\"]\n",
    "    summary = summarizer_chain.invoke({\"abstract\": abstract})\n",
    "\n",
    "    paper_with_summary = {\n",
    "        **paper,\n",
    "        \"summary_bullets\": summary\n",
    "    }\n",
    "    summarized_papers.append(paper_with_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d460c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Paper 1: Aligning Large Language Models with Healthcare Stakeholders: A Pathway to Trustworthy AI Integration\n",
      "📝 Summary:\n",
      "content=\"<think>\\nAlright, I've got this abstract to summarize into three bullet points. Let me read through it again to make sure I get the main ideas.\\n\\nThe abstract talks about large language models (LLMs) being widely explored in healthcare. It mentions that aligning these models with what healthcare stakeholders want and value is really important for effective, safe, and responsible use. But the problem is that LLMs don't always behave in ways that match what healthcare professionals know, need, or value. So, to fix this, stakeholders need to be involved in the whole process of using LLMs in healthcare—like when they're being trained, when data is being picked, and when they're actually used. The review discusses methods, tools, and applications to make sure LLMs align better with these stakeholders. They show that by integrating healthcare knowledge, understanding tasks better, and having humans guide the models, LLMs can follow human values more closely. Finally, they give ideas on how to improve this alignment to build trustworthy healthcare applications.\\n\\nSo, the key points seem to be:\\n\\n1. The importance of aligning LLMs with healthcare stakeholders' preferences.\\n2. The need for human involvement throughout the LLM lifecycle in healthcare.\\n3. Methods to enhance this alignment for trustworthy applications.\\n\\nI need to make sure each bullet point captures one of these main ideas clearly and concisely. Let me try to phrase them without being too wordy.\\n</think>\\n\\n- The alignment of large language models (LLMs) with healthcare stakeholders' preferences and values is crucial for effective, safe, and responsible integration into healthcare workflows.\\n- Human involvement is essential throughout the entire lifecycle of LLM adoption in healthcare, including data curation, training, and deployment, to ensure models meet stakeholders' needs and values.\\n- Enhancing healthcare knowledge integration, task understanding, and human guidance can improve LLM alignment with human values, leading to more trustworthy real-world healthcare applications.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 395, 'prompt_tokens': 239, 'total_tokens': 634, 'completion_time': 1.739399851, 'prompt_time': 0.022173408, 'queue_time': 0.09530401799999999, 'total_time': 1.761573259}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None} id='run--12d45872-70ac-41e7-8716-a4efc5858f6a-0' usage_metadata={'input_tokens': 239, 'output_tokens': 395, 'total_tokens': 634}\n",
      "🔗 URL: http://arxiv.org/abs/2505.02848v1\n",
      "================================================================================\n",
      "\n",
      "📘 Paper 2: An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT\n",
      "📝 Summary:\n",
      "content=\"<think>\\nAlright, so I need to summarize this abstract into three bullet points. Let me read through it again to make sure I understand all the key points. \\n\\nThe paper is about using large language models, specifically BioBERT, in healthcare. It starts by looking at previous NLP approaches in healthcare and their limitations. Then it explores how BioBERT came into play for biomedical text mining. The methodology includes gathering data from various healthcare sources, annotating data for tasks like entity recognition, and using preprocessing techniques. They also talk about evaluating the model using healthcare benchmarks and functions like question-answering and clinical document classification. There's a focus on making the model more interpretable and comparing its performance to other models. Ethical considerations like patient privacy and data security are discussed, along with benefits like better clinical support and information retrieval. However, they also mention challenges like privacy concerns, resource needs, and the necessity for customization.\\n\\nHmm, I need to condense this into three main points. The first could be about the investigation and methodology of using BioBERT in healthcare, including data collection and preprocessing. The second point should cover the evaluation and performance aspects, including benchmarks and improvements. The third point should address the ethical considerations and challenges faced during integration.\\n\\nWait, let me make sure I'm covering all the main aspects without missing anything important. The abstract mentions thorough examination of previous NLP approaches, the suitability of BioBERT, the systematic methodology, model evaluation, interpretability, ethical considerations, benefits, and challenges. I think I captured all these in the three points I outlined.\\n\\nOkay, I think that's a solid summary. Now I'll format it into three concise bullet points as requested.\\n</think>\\n\\n- The paper investigates the application of BioBERT in healthcare, exploring its suitability for biomedical text mining through a systematic methodology that includes data collection, annotation, and specialized preprocessing techniques.  \\n- It evaluates BioBERT's performance using healthcare-specific benchmarks and tasks, such as question-answering and clinical document classification, while emphasizing techniques to enhance model interpretability and comparing it to existing healthcare-focused models.  \\n- The study highlights the benefits of BioBERT in healthcare, including improved clinical decision support and information retrieval, but also addresses ethical considerations and challenges, such as patient privacy, data security, resource requirements, and the need for domain-specific customization.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 471, 'prompt_tokens': 364, 'total_tokens': 835, 'completion_time': 5.358857259, 'prompt_time': 0.029884009, 'queue_time': 0.094241478, 'total_time': 5.388741268}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None} id='run--d8aa1c08-f898-433c-8202-a7a1f92a552e-0' usage_metadata={'input_tokens': 364, 'output_tokens': 471, 'total_tokens': 835}\n",
      "🔗 URL: http://arxiv.org/abs/2310.07282v2\n",
      "================================================================================\n",
      "\n",
      "📘 Paper 3: The Role of Language Models in Modern Healthcare: A Comprehensive Review\n",
      "📝 Summary:\n",
      "content=\"<think>\\nOkay, so I need to summarize the abstract into three bullet points. Let me read it carefully first.\\n\\nThe abstract talks about large language models (LLMs) being used in healthcare. It mentions they can process complex medical data and help with clinical decisions. They're good at understanding and generating natural language, which is useful for documentation, diagnostics, and patient interaction.\\n\\nThen, the review looks at how LLMs have developed from early stages to now, highlighting their strengths in healthcare. It also discusses challenges like data privacy, bias, and ethics. Finally, it explores the potential of LLMs to improve healthcare and the steps needed to integrate them ethically and effectively.\\n\\nSo, I need to capture the main points: the use of LLMs in healthcare, their strengths, the challenges, and their potential along with integration steps.\\n\\nMaybe the first bullet can be about their application and strengths, the second about the challenges, and the third about the potential and integration.\\n\\nWait, but the user asked for three bullet points. The example response had three, each starting with a bolded key aspect. So I should structure each bullet to cover a distinct area.\\n\\nFirst bullet: Application and strengths in healthcare.\\n\\nSecond bullet: Challenges like privacy, bias, ethics.\\n\\nThird bullet: Potential to enhance healthcare and necessary steps for integration.\\n\\nThat makes sense. I should make sure each bullet is concise and covers these aspects without getting too detailed.\\n\\nI think that's a good approach. Now, I'll try to form the bullet points accordingly.\\n</think>\\n\\n- **Application and Strengths**: Large language models (LLMs) are increasingly applied in healthcare for processing complex medical data and aiding clinical decision-making. They excel in natural language understanding and generation, benefiting areas like medical documentation, diagnostics, and patient interaction.\\n\\n- **Challenges**: The use of LLMs in healthcare faces significant challenges, including data privacy concerns, potential biases, and ethical issues that must be addressed.\\n\\n- **Potential and Integration**: LLMs hold great potential to enhance healthcare delivery. Ensuring their ethical and effective integration into medical practice requires careful steps to overcome existing challenges and leverage their capabilities responsibly.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 436, 'prompt_tokens': 171, 'total_tokens': 607, 'completion_time': 2.803153049, 'prompt_time': 0.014048545, 'queue_time': 0.856609885, 'total_time': 2.817201594}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None} id='run--0592bc12-34bf-4714-8151-4f51e449114c-0' usage_metadata={'input_tokens': 171, 'output_tokens': 436, 'total_tokens': 607}\n",
      "🔗 URL: http://arxiv.org/abs/2409.16860v1\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, paper in enumerate(summarized_papers):\n",
    "    print(f\"📘 Paper {i+1}: {paper['title']}\")\n",
    "    print(f\"📝 Summary:\\n{paper['summary_bullets']}\")\n",
    "    print(f\"🔗 URL: {paper['url']}\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab597d0d",
   "metadata": {},
   "source": [
    "`Define Shared State`\n",
    "\n",
    "- LangGraph uses a shared dictionary-like state that agents can read/write.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96981930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchState(TypedDict):\n",
    "    topic: str\n",
    "    papers: Optional[List[dict]]\n",
    "    summaries: Optional[List[dict]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709976f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_node(last_message: BaseMessage, goto: str):\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        # Any agent decided the work is done\n",
    "        return END\n",
    "    return goto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d0ee262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_system_prompt(instruction: str) -> str:\n",
    "    return (\n",
    "        \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "        \" Use the provided tools to progress towards answering the question.\"\n",
    "        \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "        \" will help where you left off. Execute what you can to make progress.\"\n",
    "        \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "        \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "        f\"\\n{instruction}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13576855",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def arxiv1(topic: str, max_results: int = 2) -> str:\n",
    "    \"\"\"Fetches relevant paper abstracts from arXiv based on a topic.\"\"\"\n",
    "    papers = get_arxiv_papers(topic, max_results)\n",
    "    output = \"\"\n",
    "    for i, paper in enumerate(papers):\n",
    "        output += f\"\\n[{i+1}] {paper['title']} ({paper['published']})\\n\"\n",
    "        output += f\"Authors: {', '.join(paper['authors'])}\\n\"\n",
    "        output += f\"Abstract: {paper['summary'][:500]}...\\n\"\n",
    "        output += f\"URL: {paper['url']}\\n\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d05d1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[arxiv1],\n",
    "    prompt=make_system_prompt(\n",
    "        \"You can only do research. You are working with a summarizer colleague.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c3c6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def summarize_abstract(abstract: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarizes a research paper abstract into 3 concise bullet points.\n",
    "    \"\"\"\n",
    "\n",
    "    summary_prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are an AI research assistant. Read the abstract below and summarize the key points.\n",
    "\n",
    "    Abstract:\n",
    "    \"{abstract}\"\n",
    "\n",
    "    Summarize in 3 bullet points.\n",
    "    \"\"\")\n",
    "\n",
    "    response = summary_prompt | llm\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7f548a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[summarize_abstract],\n",
    "    prompt=make_system_prompt(\n",
    "        \"You can only summarize abstracts. Your teammate provides the abstracts.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd93fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_node(state: MessagesState) -> Command[Literal[\"summarizer\", END]]:\n",
    "\n",
    "    result = research_agent.invoke(state)\n",
    "\n",
    "    goto = get_next_node(result[\"messages\"][-1], \"summarizer\")\n",
    "\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "\n",
    "    return Command(update={\"messages\": result[\"messages\"]}, goto=goto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae2d119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizer_node(state: MessagesState) -> Command[Literal[\"researcher\", END]]:\n",
    "\n",
    "    result = summarized_agent.invoke(state)\n",
    "\n",
    "    goto = get_next_node(result[\"messages\"][-1], \"researcher\")\n",
    "\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"summarizer\")\n",
    "\n",
    "    return Command(update={\"messages\": result[\"messages\"]}, goto=goto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a241b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"researcher\", research_node)\n",
    "workflow.add_node(\"summarizer\", summarizer_node)\n",
    "\n",
    "workflow.add_edge(START, \"researcher\")\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46cb52e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d629430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\44787\\AppData\\Local\\Temp\\ipykernel_30328\\3121392185.py:9: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "no healthy upstream",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget the research paper in transformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2716\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2717\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2719\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   2720\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2721\u001b[0m     config,\n\u001b[0;32m   2722\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   2723\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   2724\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   2725\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   2726\u001b[0m     checkpoint_during\u001b[38;5;241m=\u001b[39mcheckpoint_during,\n\u001b[0;32m   2727\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   2728\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2729\u001b[0m ):\n\u001b[0;32m   2730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2731\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2732\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m   2733\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (ints \u001b[38;5;241m:=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mget(INTERRUPT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2734\u001b[0m         ):\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2435\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2436\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2437\u001b[0m             [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2438\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2439\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2440\u001b[0m             schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2441\u001b[0m         ):\n\u001b[0;32m   2442\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2443\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\pregel\\runner.py:161\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    159\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m, in \u001b[0;36msummarizer_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msummarizer_node\u001b[39m(state: MessagesState) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Command[Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresearcher\u001b[39m\u001b[38;5;124m\"\u001b[39m, END]]:\n\u001b[1;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msummarized_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     goto \u001b[38;5;241m=\u001b[39m get_next_node(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresearcher\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m HumanMessage(\n\u001b[0;32m      8\u001b[0m         content\u001b[38;5;241m=\u001b[39mresult[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarizer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2716\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2717\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2719\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   2720\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2721\u001b[0m     config,\n\u001b[0;32m   2722\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   2723\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   2724\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   2725\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   2726\u001b[0m     checkpoint_during\u001b[38;5;241m=\u001b[39mcheckpoint_during,\n\u001b[0;32m   2727\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   2728\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2729\u001b[0m ):\n\u001b[0;32m   2730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2731\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2732\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m   2733\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (ints \u001b[38;5;241m:=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mget(INTERRUPT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2734\u001b[0m         ):\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2435\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2436\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2437\u001b[0m             [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2438\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2439\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2440\u001b[0m             schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2441\u001b[0m         ):\n\u001b[0;32m   2442\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2443\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\pregel\\runner.py:161\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    159\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\utils\\runnable.py:370\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 370\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    372\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langgraph\\prebuilt\\chat_agent_executor.py:505\u001b[0m, in \u001b[0;36mcreate_react_agent.<locals>.call_model\u001b[1;34m(state, config)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_model\u001b[39m(state: StateSchema, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StateSchema:\n\u001b[0;32m    504\u001b[0m     state \u001b[38;5;241m=\u001b[39m _get_model_input_state(state)\n\u001b[1;32m--> 505\u001b[0m     response \u001b[38;5;241m=\u001b[39m cast(AIMessage, \u001b[43mmodel_runnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[0;32m    507\u001b[0m     response\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3045\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3046\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3047\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3048\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3049\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5431\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5424\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5426\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5429\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5432\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5433\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5434\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:372\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    368\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    369\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 372\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    382\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:957\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    956\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:776\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    775\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 776\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m         )\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1022\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\langchain_groq\\chat_models.py:498\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    494\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    497\u001b[0m }\n\u001b[1;32m--> 498\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:368\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    229\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    230\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    231\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msearch_settings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\groq\\_base_client.py:1225\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1213\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1220\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1222\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1223\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1224\u001b[0m     )\n\u001b[1;32m-> 1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\44787\\anaconda3\\envs\\autores-agent\\Lib\\site-packages\\groq\\_base_client.py:1034\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1031\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1033\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1034\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mInternalServerError\u001b[0m: no healthy upstream",
      "\u001b[0mDuring task with name 'agent' and id '19eb3c13-b60c-7ae6-3c22-e2c30c443dd7'",
      "\u001b[0mDuring task with name 'summarizer' and id '731eaf4f-ca09-075a-8d95-60e38067f0f5'"
     ]
    }
   ],
   "source": [
    "app.invoke({\"messages\": [(\"user\", \"get the research paper in transformer\")], })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952322fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autores-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
